\chapter{Introduction}

People re-identification (Re-ID) has been an intense research topic in recent years, the main goal of which is to match an image of a given person with other images of the same person. Person Re-ID has great potential in video surveillance, target detection and tracking, and forensic search. However, it is quite challenging since the accuracy is greatly influenced by many factors like occlusion, illumination variation, camera settings and color response. In Re-ID, those images with known labels are called gallery images, and the image used to determine its label is called a probe image. The probe image and gallery images can be from the same or different camera views, so the viewpoint and illumination between the probe and gallery image can be quite different. Also, because of the different color response of different cameras, the images of the same person may look different in different cameras. Occlusions between the camera and target can also bring about much difficulty.  In a word, images of the same person may look different while images of different persons may look quite the same. 

Given a sequence or video of individuals, there are three steps to match a person. A simple workflow is shown in Figure \ref{workflow}. However, since most Re-ID datasets are already cropped manually or by an automatic detector, most Re-ID work will only focus on robust descriptors design and efficient matching algorithm aimed at those well-cropped images. 


\begin{figure}[H]
\centering
%\begin{raggedleft}
\includegraphics[scale = 0.7]{/Users/JohnsonJohnson/Downloads/thesis_1/Figures/REIDworkflow1.pdf}
%\includegraphics[width=1\linewidth]{REIDworkflow.pdf}
\vspace{1em}
\caption{Re-ID workflow}
%\end{raggedleft}
\end{figure}
\label{workflow}

\begin{figure}[H]
\centering
%\begin{raggedleft}
\includegraphics[scale = 0.7]{/Users/JohnsonJohnson/Downloads/thesis_1/Figures/REIDworkflow2.pdf}
%\includegraphics[width=1\linewidth]{REIDworkflow.pdf}
\vspace{1em}
\caption{A typical single-shot Re-ID workflow}
%\end{raggedleft}
\end{figure}




The first task in Re-ID is to design a robust descriptor to represent images. The descriptor is supposed to contain the key information for each captured person. Basically, the descriptors are supposed to be robust and discriminative. One straightforward way is to extract the color, textural information of images and then use descriptors to compute the similarity scores. But this method turns out to be not robust to the illumination variation, camera color response difference and camera angle settings.  Therefore, many other advanced descriptors take into account the correlation of color, texture and position together to improve performance.

The second is to design the similarity computing methodology (i.e., compare the similarity of two descriptors). Previous methods use Euclidean distance, Bhattacharyya distance and Mahalanobis distance. The Euclidean distance is the easiest to match descriptors like color and texture descriptors, but not the most effective. Many creative metric learning methods have been proposed to compute descriptor similarity. Among them, the Mahalanobis distance based metric is the most popular. The goal in the Mahalanobis distance based metric is to learn a semi-positive definite (SPD) matrix $\bm{M}$, so that $\bm{M}$ satisfies predefined intraclass and interclass distance limitations.
	
\section{Basic concepts}
People re-identification can be divided into a few categories according to different conditions. Some general concepts are listed below.\\
\indent \textbf{open-set and close-set Re-ID} \cite{REIDsurvey} According to the gallery size and how the gallery size evolves, Re-ID can be divided into open-set Re-ID and close-set Re-ID. In close-set Re-ID, no new identities will be added to the gallery set, and gallery size remains the same as time goes by. Furthermore, the probe set will be a subset of the gallery set. That means, the number of unique identities in the gallery set will be equal or greater than the probe set. In open-set Re-ID, the gallery set will evolve as time goes by. Each time a probe image is entered into the recognition system, the system will judge if it has a corresponding match in the gallery set. If the probe image doesn't match any of the gallery images, it will be regarded as a new identity and will be added to the gallery set. The probe set is not necessarily the subset of the gallery set. 

\textbf{Long-term and short-term Re-ID} According to the time interval between gallery and probe images, Re-ID can be divided into long-term and short-term Re-ID.  In short-term Re-ID the time interval between gallery and probe images is small, say a few minutes or several hours. Conversely, long-term Re-ID refers to the case that the time interval between gallery and probe images is a few days or even longer. One difference to consider regarding the long time interval between gallery and probe images is the variation of individuals' clothing and appearance. If the gallery images were shot a few days prior, the same individual may have changed his suit or taken off his bag, causing the appearance to change. In this case, it will be much more difficult to recognize the same identity in long-term Re-ID. In most cases, we use short-term Re-ID, which guarantees that the appearance of the same person will remain the same and we will only need to consider the differences brought by other factors such as viewpoint variation and occlusions.


\textbf{Single-shot and multi-shot Re-ID} According to the size of the sample set for each person, Re-ID can be divided into single-shot and multi-shot approaches. In single-shot Re-ID, only one image is provided for a person in a camera view. Single-shot Re-ID is challenging because only limited information can be extracted. One example is the VIPeR dataset shown in Figure \ref{VIPeRimages}. For each person in this dataset only one image is provided in each camera view, and the viewpoint of each view is different. In multi-shot Re-ID, a sequence of images is provided for a person in a camera view. Compared with single-shot Re-ID, more information, like temporal-spatial information, can be extracted from the sample set. One example of multi-shot dataset is the prid\_2011 dataset \ref{PRID2011images}, which provides a long sequence of images for each person in a single camera view.

%-------------------------------------------------
\begin{figure}[H]

\includegraphics[width=1\linewidth]{/Users/JohnsonJohnson/Downloads/thesis_1/Figures/singleREID.eps}
\vspace{-3em}
\caption{The VIPeR dataset}
\label{VIPeRimages}
\end{figure}

%-------------------------------------------------

\begin{figure}[H]

\includegraphics[width=1\linewidth]{/Users/JohnsonJohnson/Downloads/thesis_1/Figures/Multishots.eps}
\vspace{-3em}
\caption{Samples from the prid\_2011 dataset}
\label{PRID2011images}
\end{figure}


.

\section{Challenges}

\textbf{Detection, tracking and dataset labelling for supervised learning} Though classical person re-identification focuses on robust descriptors design and matching algorithms, in real-time application, the detection and tracking has to be operated on video frames to get bounding boxes of individuals. A good detection and tracking algorithm is necessary for Re-ID. Furthermore, training the matching algorithm is a supervised process, thus we have to know the labels for those training data. 

\textbf{Descriptors design} Good descriptors should be robust to the variation of people's postures, outer environment changes and camera settings. Though there have been many kinds of descriptors based on different property like color and texture, it is hard to judge which property is universally useful for different camera settings. In fact, the robustness, reliability and feasibility depends on different camera settings and viewing conditions. What's more, the pedestrian background may add many errors to descriptors, so it is important to quantify the impact of a noisy background. Many works have tried to use a segmented foreground of pedestrians, so it is important to design segmentation algorithms. The automatic foreground segmentation for a single frame is difficult because there isn't much information available compared with video background segmentation. Take the VIPeR dataset as an example. There is only one frame for each view of a certain person, thus the segmented foreground masks are imperfect, and chances are high that important body parts will be lost. A segmented foreground provided by \cite{SDALF} is shown in Figure \ref{VIPeRFG}.
%-------------------------------------------------
\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{/Users/JohnsonJohnson/Downloads/thesis_1/Figures/FGdemo.jpg}
\vspace{-3em}
\caption{VIPeR foreground}
\label{VIPeRFG}
\end{figure}

%-------------------------------------------------
\textbf{Efficient matching algorithm design} 	
When designing machine learning algorithms to match persons, there are many limitations. One of them is the small sample size problem \cite{NFST}. The extracted descriptors usually has a high dimension $d$ but only a small number of samples $n(n<<d)$, underfitting may appear because of insufficient data samples with high dimension. It is also necessary to take into consideration intra and inter distance of samples. The intraclass distance means the distance of two samples with the same class label, while interclass distance is the distance of samples with different class labels. 

\textbf{Feasibility, complexity and scalability} When applying those descriptors and matching algorithms, we have to consider real-time performance. The Re-ID datasets usually have small sample sizes but in a surveillance network, much more pedestrians in different cameras can be presented simultaneously. A system like this has plenty of individuals to re-identify, which requires that the processing time for a single probe should be short for low latency. Because the gallery in this system evolves, it is crucial to design an algorithm that can determine if a person appearing in a current camera is new or has previously appeared in the gallery.

\section{Proposed work}
In many previous works, the kernel local Fisher discriminant analysis is used as a subspace learning method, and Euclidean distance is usually used in the subspace to measure similarity. In this thesis, the KLFDA \cite{KLFDA} method is used as a dimension-reducing method to project high-dimensional descriptors to a lower-dimensional space. Compared with other dimension reduction methods, KLFDA is a supervised method that takes into consideration of intraclass and interclass information; therefore, less information is lost after dimension reduction. A Mahalanobis distance based matrix $\bm{M}$ is learned based on the limitation that the distance of people from the same class should be at least one unit smaller than the distance of people from different classes. A target function that penalizes large intraclass distance and small interclass distance is created. When the target function converges by iterative computation, the matrix $\bm{M}$ is thought to be optimal. It turns out that this metric learning exhibits good performance when compared with other metric learning methods. A workflow of proposed work is in Figure \ref{ProposedWorkflow}.

%------------------------------------------------------------
\begin{figure}[H]

\includegraphics[width=1\linewidth]{/Users/JohnsonJohnson/Downloads/thesis_1/Figures/ProposedWorkFlow.pdf}
\vspace{-2em}
\caption{The workflow of proposed work; the left part is training and the right part is testing}
\label{ProposedWorkflow}

\end{figure}
%------------------------------------------------------------
\begin{figure}[H]

\includegraphics[width=1\linewidth]{/Users/JohnsonJohnson/Downloads/thesis_1/Figures/Multishots.eps}
\vspace{-2em}
\caption{Samples from the prid\_2011 dataset}

\end{figure}


\section{Contributions}

In this paper, we have three contributions. The first is that we combined the KLFDA with distance comparison learning. Instead of learning the subspace with KLFDA and computing Euclidean distance in a lower-dimensional space, a Mahalanobis distance based matrix is learned under the limitation that the intraclass distance is at least one unit smaller than interclass distance. Compared with those advanced metrics including cross view quadratic analysis (XQDA) \cite{LOMO} and the null Foley-Sammon transfer (NFST), this proposed metric learning proves to have excellent performance on the VIPeR, CUHK1, prid\_2011, prid\_450s and GRID dataset.

Another contribution of this thesis is the study of influence of background subtraction on different descriptors. We found that background subtraction can improve the performance of some descriptors, like the histogram of HSV colorspace, but can also decrease the performance of  other descriptors, like local binary pattern (LBP) and histogram of gradient (HOG). This comparison is shown in Chapter 3. The reason for this is that imperfect background segmentation brings in textural interference. If descriptors are color based and don't handle texture information, like HSV histogram descriptor, background segmentation can greatly improve the performance. However, if the descriptor extracts texture information, background segmentation will decrease its performance since the imperfect segmentation will mask out many parts of the foreground area, which will cause important textural information variation. Because segmentation algorithms will cause different influence on various features, in this thesis, a weighted map of images is used instead of using the background segmentation.

For the last contribution, some variants of hierarchical Gaussian descriptor have been tested. In one variant, LBP was used in the basic pixel feature. In another variant, superpixel segmentation was also applied to combine with hierarchical Gaussian descriptor, which implied that overlapping patch sampling is important in a hierarchical Gaussian descriptor. At last, the Gaussian mixture model (GMM) was also tested but it displayed the worst performance.

\section{Thesis organization}
In this thesis, Chapter 2 will give a brief introduction of previous work. Chapter 3 will explain the implementation of the hierarchical Gaussian descriptors used in this thesis. The performance of some variants of the hierarchical Gaussian descriptor is studied in this chapter. In Chapter 4, a detailed introduction of the kernel local Fisher discriminant analysis will be presented, and a detailed explanation of the metric learning on the lower-dimensional space based on relative distance limitation learning will also be provided.
In Chapter 5, the used datasets and parameters and other experiment settings will be explained, and a detailed analysis of results will be presented there. Finally, the conclusion is given in Chapter 6.




